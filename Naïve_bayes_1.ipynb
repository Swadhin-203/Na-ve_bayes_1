{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e42f6cb8-7338-4602-a90a-7fd2077cc137",
   "metadata": {},
   "source": [
    "# Q1. What is Bayes' theorem?\n",
    "\n",
    "Bayes' theorem, named after the Reverend Thomas Bayes, is a fundamental principle in probability theory and statistics. It describes the probability of an event, based on prior knowledge of conditions that might be related to the event. The theorem is expressed mathematically as:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\r\n",
    "\r\n",
    "Here's what each term represents:\r\n",
    "\r\n",
    "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred (this is called the posterior probability).\r\n",
    "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred (this is called the likelihood).\r\n",
    "- \\( P(A) \\) is the prior probability of event A.\r\n",
    "- \\( P(B) \\) is the prior probability of event B.\r\n",
    "\r\n",
    "In simple terms, Bayes' theorem allows you to update your belief in the probability of an event A based on the occurrence of another event B and the prior probabilities of A and B. It's widely used in various fields, including statistics, machine learning, and artificial intelligence. Bayesian inference, which involves updating probabilities as new evidence becomes available, is a key application of Bayes' theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6de56-ae57-4b29-9fc3-be5bd7057a9a",
   "metadata": {},
   "source": [
    "# Q2. What is the formula for Bayes' theorem?\n",
    "The formula for Bayes' theorem is:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\r\n",
    "\r\n",
    "Here's a breakdown of the terms in the formula:\r\n",
    "\r\n",
    "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred. This is the posterior probability.\r\n",
    "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred. This is the likelihood.\r\n",
    "- \\( P(A) \\) is the prior probability of event A.\r\n",
    "- \\( P(B) \\) is the prior probability of event B.\r\n",
    "\r\n",
    "In words, Bayes' theorem allows you to update your belief in the probability of an event A based on the occurrence of another event B and the prior probabilities of A and B. It's a fundamental concept in probability theory and is widely used in various fields for reasoning under uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3811b-bb76-4f9a-911c-2215de3a5a99",
   "metadata": {},
   "source": [
    "# Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Bayes' theorem is used in various practical applications, particularly in fields where uncertainty and probability play a role. Here are a few examples of how Bayes' theorem is used in practice:\r\n",
    "\r\n",
    "1. **Medical Diagnosis:**\r\n",
    "   - Bayes' theorem is used in medical diagnosis to update the probability of a particular disease given new diagnostic information.\r\n",
    "   - For example, if a patient tests positive for a certain medical condition, Bayes' theorem can be used to calculate the probability that the patient actually has the condition, taking into account the sensitivity and specificity of the test.\r\n",
    "\r\n",
    "2. **Spam Filtering:**\r\n",
    "   - In email spam filtering, Bayes' theorem is applied to calculate the probability that an incoming email is spam based on certain characteristics (words, phrases, etc.).\r\n",
    "   - The filter is trained on a set of known spam and non-spam emails to calculate prior probabilities, and then it updates these probabilities as new emails are received.\r\n",
    "\r\n",
    "3. **Machine Learning:**\r\n",
    "   - Bayes' theorem is a fundamental concept in Bayesian machine learning. It is used in Bayesian inference to update probabilities of hypotheses as new data becomes available.\r\n",
    "   - Bayesian methods are applied in various machine learning models, including Naive Bayes classifiers and Bayesian networks.\r\n",
    "\r\n",
    "4. **Finance:**\r\n",
    "   - In finance, Bayes' theorem can be used for risk assessment and portfolio management.\r\n",
    "   - It helps update the probabilities of different financial events based on new market information, assisting in making more informed investment decisions.\r\n",
    "\r\n",
    "5. **Quality Control:**\r\n",
    "   - Bayes' theorem is used in quality control to update the probability that a manufactured product is defective based on inspection results.\r\n",
    "   - It helps in making decisions about whether a production process needs adjustment or if the product meets quality standards.\r\n",
    "\r\n",
    "6. **Natural Language Processing:**\r\n",
    "   - In natural language processing, Bayes' theorem can be used for text classification, sentiment analysis, and other tasks.\r\n",
    "   - It helps calculate the probability that a given document belongs to a particular category based on the occurrence of certain words or features.\r\n",
    "\r\n",
    "In essence, Bayes' theorem provides a framework for updating probabilities in light of new evidence, making it a valuable tool for reasoning under uncertainty in various practical scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074acfc0-3881-446a-9af2-1623e7b5a700",
   "metadata": {},
   "source": [
    "# Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "Bayes' theorem is closely related to conditional probability. In fact, Bayes' theorem can be derived from the definition of conditional probability.\r\n",
    "\r\n",
    "Conditional probability is the probability of an event occurring given that another event has already occurred. It is denoted as \\(P(A|B)\\) and is read as \"the probability of event A given event B.\" The formula for conditional probability is:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\]\r\n",
    "\r\n",
    "Here, \\(P(A \\cap B)\\) is the probability that both events A and B occur, and \\(P(B)\\) is the probability that event B occurs.\r\n",
    "\r\n",
    "Bayes' theorem can be derived from the definition of conditional probability by rearranging the terms. Starting with the definition of conditional probability:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\]\r\n",
    "\r\n",
    "You can rearrange this equation to obtain Bayes' theorem:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\r\n",
    "\r\n",
    "Here's how the terms in Bayes' theorem relate to conditional probability:\r\n",
    "\r\n",
    "- \\( P(A|B) \\) is the posterior probability, the probability of event A occurring given that event B has occurred.\r\n",
    "- \\( P(B|A) \\) is the likelihood, the probability of event B occurring given that event A has occurred.\r\n",
    "- \\( P(A) \\) is the prior probability, the initial probability of event A.\r\n",
    "- \\( P(B) \\) is the prior probability of event B.\r\n",
    "\r\n",
    "In summary, Bayes' theorem provides a way to update the probability of an event based on new evidence, and it is built upon the concept of conditional probability. The theorem is a powerful tool for reasoning under uncertainty and is widely used in statistics, machine learning, and various other fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6390a-1189-47ca-8fd1-f9a1bb4a948b",
   "metadata": {},
   "source": [
    "# Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "The choice of which type of Naive Bayes classifier to use for a given problem depends on the nature of the data and the assumptions you are willing to make about the independence of features. There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here's a brief overview of each type and some considerations for choosing the appropriate one:\r\n",
    "\r\n",
    "1. **Gaussian Naive Bayes:**\r\n",
    "   - Assumes that the features follow a normal distribution.\r\n",
    "   - Suitable for continuous data.\r\n",
    "   - Commonly used in problems where features are real-valued, such as in natural language processing tasks with word frequencies.\r\n",
    "\r\n",
    "2. **Multinomial Naive Bayes:**\r\n",
    "   - Assumes that the features are generated from a multinomial distribution (commonly used for discrete data).\r\n",
    "   - Suitable for problems with discrete features (e.g., word counts in document classification).\r\n",
    "   - Often used in text classification tasks.\r\n",
    "\r\n",
    "3. **Bernoulli Naive Bayes:**\r\n",
    "   - Assumes that features are binary (0 or 1), representing the absence or presence of a particular feature.\r\n",
    "   - Suitable for binary or boolean features.\r\n",
    "   - Commonly used in problems like document classification where each term's presence or absence is considered.\r\n",
    "\r\n",
    "Factors to consider when choosing the type of Naive Bayes classifier:\r\n",
    "\r\n",
    "- **Nature of the Data:**\r\n",
    "  - If your features are continuous and approximately follow a normal distribution, Gaussian Naive Bayes may be appropriate.\r\n",
    "  - If your features are counts or frequencies (e.g., word occurrences), Multinomial Naive Bayes is often a good choice.\r\n",
    "  - For binary features, where you're interested in whether a feature is present or not, Bernoulli Naive Bayes may be suitable.\r\n",
    "\r\n",
    "- **Assumptions about Independence:**\r\n",
    "  - The \"Naive\" in Naive Bayes comes from the assumption that features are conditionally independent given the class. If this assumption doesn't hold, the classifier might not perform well.\r\n",
    "  - In practice, Naive Bayes classifiers can still work well even when the independence assumption is violated, especially in high-dimensional spaces.\r\n",
    "\r\n",
    "- **Size of the Dataset:**\r\n",
    "  - If you have a small dataset, simpler models like Naive Bayes can be beneficial due to their lower risk of overfitting.\r\n",
    "\r\n",
    "- **Computational Efficiency:**\r\n",
    "  - Naive Bayes classifiers are computationally efficient and can be trained quickly, making them suitable for large datasets.\r\n",
    "\r\n",
    "It's often a good idea to try different types of Naive Bayes classifiers and compare their performance on a validation set to determine which one works best for your specific problem. The choice can depend on the characteristics of your data and the goals of your classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098576a8-eca9-4fa8-af56-e51bf1d4a0a7",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cf53e53-ed05-4295-a78f-7ce52f4be091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Naive Bayes classifier predicts that the new instance belongs to Class A.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "\n",
    "# Given dataset\n",
    "X = np.array([[1, 4], [2, 3], [3, 3], [3, 3], [2, 2], [1, 2], [3, 2]])\n",
    "y = np.array(['A', 'A', 'A', 'A', 'B', 'B', 'B'])\n",
    "\n",
    "# Create and fit the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "model.fit(X, y)\n",
    "\n",
    "# New instance\n",
    "new_instance = np.array([[3, 4]])\n",
    "\n",
    "# Predict the class\n",
    "predicted_class = model.predict(new_instance)\n",
    "\n",
    "print(f\"The Naive Bayes classifier predicts that the new instance belongs to Class {predicted_class[0]}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c642c-592f-4764-9e65-b135fe0e58a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a157fd-6d06-46d9-a032-9d82e84a6ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad300d5-41f0-4c40-9ecc-c733dea288d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ddff7-e10c-4ac2-8995-f5aafbce365b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cf906-e20d-4123-bac5-6ff8985dd80d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b267d7-1b12-4cf0-bf29-1532a4b54635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770560d3-5415-4662-bf51-1bf593ec3f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b10184-e62a-4adb-a4c9-168b4bf5f7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec46ad-e474-46dc-92fd-66ca183a560e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f74725-54e6-47d5-86cf-dcc49c2d9d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71e58a-25b2-477d-b93b-477e78bda019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa3110-d0df-4b5a-997d-376243051988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34582bb-2ca5-4358-81ea-8059cbd41e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e45ac-4f86-4a6f-8781-f376608acf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b132ce-3e13-4904-a67c-cbddcbf0dbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebec8e9d-0f47-4248-b7bd-96c65f577a34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4753ca2-9818-41f3-ae2f-2a480e8f8485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad78a7-778b-4474-a993-8090553d5f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1de959-87bf-4299-a9ca-821511f42294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
